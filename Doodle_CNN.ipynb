{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doodle_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JE4RHgLmBrU"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS8mA8O2mMta"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "!pip install ndjson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEKmolaemT-s"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVylRJaXmXnr"
      },
      "source": [
        "a=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_airplane.npy')\n",
        "b=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_ant.npy')\n",
        "c=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_banana.npy')\n",
        "d=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_baseball.npy')\n",
        "e=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_bird.npy')\n",
        "f=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_bucket.npy')\n",
        "g=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_butterfly.npy')\n",
        "h=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_cat.npy')\n",
        "i=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_coffee cup.npy')\n",
        "j=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_dolphin.npy')\n",
        "k=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_donut.npy')\n",
        "l=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_duck.npy')\n",
        "m=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_fish.npy')\n",
        "n=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_leaf.npy')\n",
        "o=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_mountain.npy')\n",
        "p=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_pencil.npy')\n",
        "q=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_smiley face.npy')\n",
        "r=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_snake.npy')\n",
        "s=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_umbrella.npy')\n",
        "t=np.load('/content/drive/MyDrive/Doodle dataset/Doodle dataset.rar (Unzipped Files)/full_numpy_bitmap_wine bottle.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn_4QVZJmglz"
      },
      "source": [
        "data_conc=np.concatenate((a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WIZocaXmzzC"
      },
      "source": [
        "a_label=np.full([151623, 1],0,dtype=int)\n",
        "b_label=np.full([b.shape[0], 1], 1, dtype=int)\n",
        "c_label=np.full([c.shape[0], 1], 2, dtype=int)\n",
        "d_label=np.full([d.shape[0], 1], 3, dtype=int)\n",
        "e_label=np.full([e.shape[0], 1], 4, dtype=int)\n",
        "f_label=np.full([f.shape[0], 1], 5, dtype=int)\n",
        "g_label=np.full([g.shape[0], 1], 6, dtype=int)\n",
        "h_label=np.full([h.shape[0], 1], 7, dtype=int)\n",
        "i_label=np.full([i.shape[0], 1], 8, dtype=int)\n",
        "j_label=np.full([j.shape[0], 1], 9, dtype=int)\n",
        "k_label=np.full([k.shape[0], 1], 10, dtype=int)\n",
        "l_label=np.full([l.shape[0], 1], 11, dtype=int)\n",
        "m_label=np.full([m.shape[0], 1], 12, dtype=int)\n",
        "n_label=np.full([n.shape[0], 1], 13, dtype=int)\n",
        "o_label=np.full([o.shape[0], 1], 14, dtype=int)\n",
        "p_label=np.full([p.shape[0], 1], 15, dtype=int)\n",
        "q_label=np.full([q.shape[0], 1], 16, dtype=int)\n",
        "r_label=np.full([r.shape[0], 1], 17, dtype=int)\n",
        "s_label=np.full([s.shape[0], 1], 18, dtype=int)\n",
        "t_label=np.full([t.shape[0], 1], 19, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PFZTmdbnOZe"
      },
      "source": [
        "label_conc=np.concatenate((a_label,b_label,c_label,d_label,e_label,f_label,g_label,h_label,i_label,j_label,k_label,l_label,m_label, n_label,o_label,p_label,q_label,r_label,s_label, t_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEH077w4nWk8"
      },
      "source": [
        "a1=np.arange(0,2807037)\n",
        "np.random.shuffle(a1)\n",
        "data_conc=data_conc[a1,:]\n",
        "label_conc=label_conc[a1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gHw4pgnna3a"
      },
      "source": [
        "batch_size=4096\n",
        "learning_rate=0.01\n",
        "num_epochs=10\n",
        "\n",
        "class Data_train(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x= data_conc[:2045200,:].reshape(2045200,1,28,28)\n",
        "    self.y= label_conc[:2045200,:].reshape(2045200,)\n",
        "    self.n= data_conc[:2045200,:].shape[0]\n",
        "  def __getitem__(self,i):\n",
        "    return self.x[i],self.y[i]\n",
        "  def __len__(self):\n",
        "    return self.n\n",
        "data_train=Data_train()\n",
        "dataloader_train=DataLoader(data_train,batch_size=4096,shuffle=True)\n",
        "\n",
        "class Data_test(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x= data_conc[2045200:,:].reshape(2807037-2045200,1,28,28)\n",
        "    self.y= label_conc[2045200:,:].reshape(2807037-2045200,)\n",
        "    self.n= data_conc[2045200:,:].shape[0]\n",
        "  def __getitem__(self,i):\n",
        "    return self.x[i],self.y[i]\n",
        "  def __len__(self):\n",
        "    return self.n\n",
        "data_test=Data_test()\n",
        "dataloader_test=DataLoader(data_test,batch_size=4096,shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqMnZSbAnfn2"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1=nn.Conv2d(1, 6, 5)\n",
        "    self.pool=nn.MaxPool2d(2,2)\n",
        "    self.conv2=nn.Conv2d(6, 16, 5)\n",
        "    self.fc1=nn.Linear(16*4*4, 120)\n",
        "    self.fc2=nn.Linear(120, 84)\n",
        "    self.fc3=nn.Linear(84, 20)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.pool(F.relu(self.conv1(x)))\n",
        "    x=self.pool(F.relu(self.conv2(x)))\n",
        "    x=x.view(-1, 16*4*4)\n",
        "    \n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "\n",
        "model=ConvNet().to(device)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses = []\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McPC_UyWnjny"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(dataloader_train):\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    outputs=model(images.float())\n",
        "\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%100 == 0:\n",
        "      print(f'Training Epoch[{epoch+1}/{num_epochs}],loss:{loss.item():.4f}')\n",
        "\n",
        "  train_losses.append(loss.item())\n",
        "\n",
        "print('Finished training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6JCaNDpnumB"
      },
      "source": [
        "def test(): \n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in (dataloader_test):\n",
        "      images=images.to(device)\n",
        "      labels=labels.to(device)\n",
        "      outputs = model(images.float())\n",
        "\n",
        "      _,predictions = torch.max(outputs, 1) \n",
        "      n_samples += labels.shape[0]\n",
        "      n_correct += (predictions == labels).sum().item()\n",
        "  \n",
        "    acc = 100* n_correct / n_samples\n",
        "    print(f'Test accuracy = {acc:.4f}')\n",
        "\n",
        "def train(): \n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in (dataloader_train):\n",
        "      images=images.to(device)\n",
        "      labels=labels.to(device)\n",
        "      outputs = model(images.float())\n",
        "\n",
        "      _,predictions = torch.max(outputs, 1) \n",
        "      n_samples += labels.shape[0]\n",
        "      n_correct += (predictions == labels).sum().item()\n",
        "  \n",
        "    acc = 100* n_correct / n_samples\n",
        "    print(f'Training accuracy = {acc:.4f}')\n",
        "\n",
        "train()\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_4nE4JGn4vm"
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"batch size 4096, lr 0.01, epochs 10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ull6NGBVoN0x"
      },
      "source": [
        "#saving model\n",
        "FILE = \"model1.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "#loading model for evalution \n",
        "FILE = \"model1.pth\"\n",
        "loaded_model = ConvNet()\n",
        "loaded_model.load_state_dict(torch.load(FILE)) \n",
        "loaded_model.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZiPU3u_oZlx"
      },
      "source": [
        "#testing\n",
        "import random\n",
        "i=np.random.randint(1,2807037)\n",
        "img=torch.tensor(data_conc[i]).to(device).float()\n",
        "img=img.reshape(1,1,28,28)\n",
        "l=label_conc[i]\n",
        "res=loaded_model(img)\n",
        "i=torch.argmax(res)\n",
        "\n",
        "\n",
        "plt.imshow(img.to('cpu').detach().numpy().reshape(28,28))\n",
        "print(\"it's a \",classes[i.item()])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}